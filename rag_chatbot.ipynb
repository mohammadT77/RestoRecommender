{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WJdr4FOV3m1",
        "outputId": "119f9efd-5cf0-4670-f37c-29bc797e5e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.1.0 requires langchain-core<0.2,>=0.1.7, but you have langchain-core 0.2.1 which is incompatible.\n",
            "langchain 0.1.0 requires langsmith<0.1.0,>=0.0.77, but you have langsmith 0.1.63 which is incompatible.\n",
            "langchain-community 0.0.12 requires langchain-core<0.2,>=0.1.9, but you have langchain-core 0.2.1 which is incompatible.\n",
            "langchain-community 0.0.12 requires langsmith<0.1.0,>=0.0.63, but you have langsmith 0.1.63 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q \\\n",
        "    transformers==4.31.0 \\\n",
        "    accelerate==0.21.0 \\\n",
        "    bitsandbytes==0.41.0 \\\n",
        "    sentence-transformers==2.2.2 \\\n",
        "    xformers==0.0.20 \\\n",
        "\n",
        "!pip install -q \\\n",
        "    langchain==0.1.0 \\\n",
        "    langchain-community==0.0.12 \\\n",
        "    langchainhub==0.1.14 \\\n",
        "    faiss-gpu \\\n",
        "    faiss-cpu\n",
        "\n",
        "!pip install -q pandas\n",
        "# !pip install -q colab-xterm\n",
        "!pip install -qU langchain-anthropic\n",
        "!pip install -q python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "IVZTYMYqhEyD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    ChatPromptTemplate,)\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders.dataframe import DataFrameLoader\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import huggingface_hub as hf_hub\n",
        "\n",
        "try:\n",
        "    from google.colab.userdata import get as getenv\n",
        "except ImportError:\n",
        "    from os import getenv\n",
        "    import dotenv\n",
        "    dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from torch import cuda\n",
        "    device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "except ImportError:\n",
        "    device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wj12nPpoijV",
        "outputId": "62d61f31-5786-4169-d678-2c2137fada1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /home/codespace/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "HF_TOKEN = getenv('HF_TOKEN')\n",
        "assert HF_TOKEN, \"A valid HuggingFace token is required to be set as <HF_TOKEN>.\"\n",
        "hf_hub.login(HF_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "ANTHROPIC_API_KEY = getenv('ANTHROPIC_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rzeDBNMoijW"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TeXyY2YLWqcD"
      },
      "outputs": [],
      "source": [
        "# Dataset files\n",
        "PLACES_PATH = \"data/places.csv\"\n",
        "REVIEWS_PATH = \"data/reviews.csv\"\n",
        "\n",
        "# Models\n",
        "MODEL_NAME =  \"meta-llama/Llama-2-7b-hf\" # \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "# Embeddings\n",
        "EMBEDDINGS_CACHE_STORE=\"./cache/\"\n",
        "\n",
        "# Faiss\n",
        "FAISS_REVIEWS_PATH = \"faiss_index\"\n",
        "FAISS_INDEX_NAME = \"index\"\n",
        "FAISS_DISTANCE_STRATEGY='EUCLIDEAN_DISTANCE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUr5hUrPoijY"
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "Here we are using 2 csv files containing places (restuarants, bars, ...) info and reviews for each of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aONHvzXAoijZ"
      },
      "outputs": [],
      "source": [
        "def get_documents(content_func=lambda row:row['review'],\n",
        "                  source_func=lambda row:row['place_id'],\n",
        "                  metadata_fields=[]):\n",
        "\n",
        "  # Load both data files\n",
        "  places_df = pd.read_csv(PLACES_PATH)\n",
        "  reviews_df = pd.read_csv(REVIEWS_PATH)\n",
        "\n",
        "  # merge them on 'place_id'\n",
        "  merged_df = pd.merge(places_df, reviews_df, on='place_id', how='inner')\n",
        "\n",
        "  # add page_content and source columns using their corresponing functions\n",
        "  merged_df['page_content'] = merged_df.apply(content_func, axis=1)\n",
        "  merged_df['source'] = merged_df.apply(source_func, axis=1)\n",
        "\n",
        "  # update metadata_fields with 'page_content', 'source'\n",
        "  metadata_fields = list(set(metadata_fields + ['page_content', 'source']))\n",
        "\n",
        "  loader = DataFrameLoader(merged_df[metadata_fields],page_content_column='page_content')\n",
        "  return loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "E5jUkJ8XoijZ"
      },
      "outputs": [],
      "source": [
        "def content_func(row) -> str:\n",
        "  content_fields = ['place_name', 'place_types', 'place_address', 'place_average_ratings', 'review']\n",
        "  return '\\n'.join(f\"{key}={row[key]}\" for key in content_fields)\n",
        "\n",
        "documents = get_documents(content_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH4HR9emoijZ",
        "outputId": "fa47e9ba-3bdf-4c36-c553-300479119540"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='place_name=Roemerkeller Padova\\nplace_types=[\\'italian_restaurant\\', \\'steak_house\\', \\'pizza_restaurant\\', \\'meal_takeaway\\', \\'restaurant\\', \\'food\\', \\'point_of_interest\\', \\'establishment\\']\\nplace_address=Via Romana Aponense, 137, 35142 Padova PD, Italy\\nplace_average_ratings=4.0\\nreview=Huge \"eating palace\" which is lacking the fine accents of the italian food although the service was top. I would recommend for lunch, less for dinner', metadata={'source': 'ChIJpXSgrsDbfkcRzf_5kCMmrZI'})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLU4f9yqoija"
      },
      "source": [
        "## Load Embeddings model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vgtePYxKoija"
      },
      "outputs": [],
      "source": [
        "def get_hf_embedding_model(embedding_model_name,\n",
        "                           cache_embeddings_store,\n",
        "                           device='cpu',\n",
        "                           normalize_embeddings=False,\n",
        "                           ):\n",
        "  model_kwargs = {'device': device}\n",
        "  encode_kwargs = {'normalize_embeddings': normalize_embeddings} # Set `True` for cosine similarity\n",
        "  embedding_model = HuggingFaceEmbeddings(\n",
        "      model_name=embedding_model_name,\n",
        "      model_kwargs=model_kwargs,\n",
        "      encode_kwargs=encode_kwargs\n",
        "      )\n",
        "  store = LocalFileStore(cache_embeddings_store)\n",
        "  embedding_model = CacheBackedEmbeddings.from_bytes_store(\n",
        "                    embedding_model, store)\n",
        "  return embedding_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mIsrrLWnoijg"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e18e3016a5a74d58ad6ad1bb1439edd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58e1a6ac91c2444dae5ada567d18d2ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d028f8cc00bc4c04af88d7ad27471f98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef04962e9f854b3db59cf2d8ed8b2bc5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f43320913214722950cfc31a4a05250",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b053bc91b9b3452586af65d37c259412",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0309ebf56e146ca9629fb95d00152d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5306fc21a82a462f85ad24aecef081ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0e0b5a1eea4d58aac14870d96ab519",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8108381eeb1846e887ed13bcf5ab4079",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "096956680146448992e5cac3bc36c312",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8ffd7cb480744c1b5d141c5d6383d67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4758491ce7634a38848e6662487d298d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22d603077eaf414eb65a03b1c3322efc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e7948b13c324009b2746f77eb19cb6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embedding_model = get_hf_embedding_model(EMBEDDING_MODEL_NAME,\n",
        "                                         EMBEDDINGS_CACHE_STORE,\n",
        "                                         device=device,\n",
        "                                         normalize_embeddings=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZU69PxDoijg"
      },
      "source": [
        "## Load FAISS (Vector Database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ClgYJkU5oijj"
      },
      "outputs": [],
      "source": [
        "def get_vector_database(documents, embedding_model):\n",
        "\n",
        "  vector_database = FAISS.from_documents(\n",
        "      documents, embedding_model,\n",
        "      distance_strategy= FAISS_DISTANCE_STRATEGY\n",
        "      )\n",
        "  return vector_database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZY6Ku6Eboijj"
      },
      "outputs": [],
      "source": [
        "vector_db = get_vector_database(documents, embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "A_kv8O3zndtA"
      },
      "outputs": [],
      "source": [
        "## if you want to save the db and use the files to load it again later.\n",
        "vector_db.save_local(folder_path=FAISS_REVIEWS_PATH, index_name=FAISS_INDEX_NAME)\n",
        "vector_db = FAISS.load_local(folder_path=FAISS_REVIEWS_PATH,\n",
        "                             embeddings=embedding_model,\n",
        "                             index_name=FAISS_INDEX_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "SzaIRkhToijm"
      },
      "outputs": [],
      "source": [
        "docs = vector_db.similarity_search(\"which one is the best pizza restaurant in the city?\", k = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9xMBNVuoijt",
        "outputId": "9fa4cbc2-084d-4f1f-e891-6e00f457e0fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content=\"place_name=Bar Ristorante Pizzeria Otivm Lunch Cafe'\\nplace_types=['bar', 'hamburger_restaurant', 'vegan_restaurant', 'fast_food_restaurant', 'vegetarian_restaurant', 'sandwich_shop', 'american_restaurant', 'restaurant', 'food', 'point_of_interest', 'establishment']\\nplace_address=Via Roma, 69, 35122 Padova PD, Italy\\nplace_average_ratings=4.4\\nreview=Hands down one of the BEST PIZZA I ever had! The place can get busy so donâ€™t expect chit-chat, but totally worth it! Thank you for this culinary experience! ðŸ™ŒðŸ»\", metadata={'source': 'ChIJtSDfulHafkcRXqCEUnZKrN0'})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk1-sq8Voijw"
      },
      "source": [
        "### Load LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uOGUVg7uw4hP"
      },
      "outputs": [],
      "source": [
        "def get_claude_api_llm(model_name):\n",
        "  llm = ChatAnthropic(model_name=model_name, anthropic_api_key=ANTHROPIC_API_KEY,)\n",
        "\n",
        "  return llm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GgNq7ELyoijx"
      },
      "outputs": [],
      "source": [
        "def get_hf_llm(model_name):\n",
        "\n",
        "  bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_use_double_quant=True,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "  )\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, )\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "  pipe = pipeline(\n",
        "      model=model,\n",
        "      tokenizer=tokenizer,\n",
        "      return_full_text=True,  # langchain expects the full text\n",
        "      task='text-generation',\n",
        "      # we pass model parameters here too\n",
        "      temperature=0.0001,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
        "      max_new_tokens=512,  # mex number of tokens to generate in the output\n",
        "      repetition_penalty=1.1  # without this output begins repeating\n",
        "  )\n",
        "\n",
        "  llm = HuggingFacePipeline(pipeline=pipe,)\n",
        "  return llm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "grd0zxY9oijy"
      },
      "outputs": [],
      "source": [
        "llm = get_claude_api_llm(\"claude-3-sonnet-20240229\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0ySJ4wyv78o",
        "outputId": "ca910516-7310-4ccb-8e57-c0bdfa3d5a85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', response_metadata={'id': 'msg_01XBLgSVfSMjQmXuagGxZNWS', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 8, 'output_tokens': 12}}, id='run-a5843c54-f15b-4e49-b9df-71c55c357345-0')"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"Hi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4SU2uzJoijz"
      },
      "source": [
        "## Create LangChain pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GNPL6u4EkAW3"
      },
      "outputs": [],
      "source": [
        "review_template_str = \"\"\"Your job is to use Google Map\n",
        "reviews to answer questions about their experience at a restaurant. Use\n",
        "the following context to answer questions. Be as detailed as possible, but\n",
        "don't make up any information that's not from the context. If you don't know\n",
        "an answer based on the context, say you don't know.\n",
        "context:\n",
        "{context}\n",
        "\"\"\"\n",
        "## \"\"\"\n",
        "# If you don't know an answer based on the context, say you don't know, and\n",
        "# if the context is not about restaurants, then kindly tell them that  you can\n",
        "# only provide assistance and answer questions related to restaurants.\n",
        "##\"\"\"\n",
        "\n",
        "review_system_prompt = SystemMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"context\"], template=review_template_str\n",
        "    )\n",
        ")\n",
        "\n",
        "review_human_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(input_variables=[\"question\"], template=\"{question}\")\n",
        ")\n",
        "messages = [review_system_prompt, review_human_prompt]\n",
        "\n",
        "review_prompt_template = ChatPromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"], messages=messages\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "reviews_retriever = vector_db.as_retriever(k=10,)\n",
        "\n",
        "review_chain = (\n",
        "    {\"context\": reviews_retriever, \"question\": RunnablePassthrough()}\n",
        "    | review_prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32GruWzvuWnM",
        "outputId": "b53bc31b-0755-4fe6-99ce-5539fccb8b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unfortunately, there is no specific review or information provided about the \"best pizza restaurant\" in the city. The context has reviews for several restaurants, including a wine bar with excellent pizza, a hamburger restaurant, and a restaurant specializing in Neapolitan pizza. However, none of them are explicitly stated as being the best pizza restaurant. Without more details identifying which restaurant is considered the best for pizza, I cannot provide a detailed overview of the pros and cons based on the given information.\n"
          ]
        }
      ],
      "source": [
        "# review_chain = (\n",
        "#     {\"context\": reviews_retriever, \"question\": RunnablePassthrough()}\n",
        "#     | review_prompt_template\n",
        "# )\n",
        "\n",
        "question = \"\"\"What are the pros and cons of the best pizza restaurant in the city?\"\"\"\n",
        "print(review_chain.invoke(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzzRDTT6tTrt",
        "outputId": "2ea12f61-646e-45fb-839c-595749536e43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"place_name=McDonald's\\nplace_types=['fast_food_restaurant', 'hamburger_restaurant', 'american_restaurant', 'restaurant', 'food', 'point_of_interest', 'establishment']\\nplace_address=Piazzale della Stazione, 5, 35131 Padova PD, Italy\\nplace_average_ratings=3.2\\nreview=I would say the services and staff are nice. The place is cozy and clean and has seats to sit and enjoy your meal.\\nBut I wasn't satisfied with the taste of the food. I ordered a cheeseburger but honestly, it was not tasty as my experience in other McDonald's around Europe, Russia, and the US.\\nBefore I was thinking of visiting at least once a week, but now I just visited once and not planning to visit that much soon.\\n\\nSince that, I am a big fan of McDonald's I always expect a better taste and products but this one was not my story of eating at McDonald's.\", metadata={'source': 'ChIJndkoTl3afkcRDto-rckMt7o'}),\n",
              " Document(page_content=\"place_name=Enoteca Barcollo\\nplace_types=['bar', 'food', 'point_of_interest', 'establishment']\\nplace_address=Via Alessandro Guidi, 23, 35142 Padova PD, Italy\\nplace_average_ratings=4.3\\nreview=Wine shop with quality wines and cicchetti and THE BEST PIZZA I HAVE TASTED IN RECENT YEARS\\n\\nSmall place, but furnished correctly and with the right distribution of spaces.\\nWide choice of wines excellently recommended by the two landladies.\\nQuality cicchetti with a refined and non-trivial choice of ingredients.\\nAffordable and above all correct prices compared to the quality of the offer.\\n\\nIf that wasn't enough, they have the best pizza I've tasted in years. Undoubted quality of the flours, wholemeal dough perfectly balanced in terms of crunchiness, thickness and flavour. The rest of the ingredients are no different. The pizza is not large and costs â‚¬9, but personally I would be willing to pay more.\\nP.S. My girlfriend doesn't like pizza - here we were on the verge of ordering another one and she was okay with it.\", metadata={'source': 'ChIJwzs5vKLbfkcRp43hqXskPKw'}),\n",
              " Document(page_content=\"place_name=Soul Kitchen\\nplace_types=['hamburger_restaurant', 'fast_food_restaurant', 'american_restaurant', 'bar', 'restaurant', 'food', 'point_of_interest', 'establishment']\\nplace_address=Via del Santo, 23, 35123 Padova PD, Italy\\nplace_average_ratings=4.6\\nreview=I got a tip to eat here from a local as my need was to eat food fast.\\n\\nThe glass of wine was nice, the burger was fair in quality. I tried the carbonara burger. Taste experience-wise, I was not too impressed and I feel the price for the offer was on the high end (14 euro) for not including fries.\\n\\nThe staff was helpful and the place has a nice atmosphere.\", metadata={'source': 'ChIJP-ZEOlTafkcRFi8zBVerMvg'}),\n",
              " Document(page_content='place_name=Ristorante Napoli Centrale\\nplace_types=[\\'pizza_restaurant\\', \\'italian_restaurant\\', \\'restaurant\\', \\'food\\', \\'point_of_interest\\', \\'establishment\\']\\nplace_address=Via S. Fermo, 59, 35137 Padova PD, Italy\\nplace_average_ratings=4.1\\nreview=I wanted to try \"pizza fritti\", a Napoli deep fried pizza, and having had traditional pizza in Naples earlier in the week this was my chance.\\n\\nThis busy pizza restaurant delivered the goods with a hot, melty, cheesy package, rather like a savory donut on steroids.\\n\\nIt was a little too much food for me, but worth trying once. The mozzarella, ricotta, tomato, and cotton ham filling was salty and tasty.', metadata={'source': 'ChIJX1jA6FvbfkcRk6FcFeIO7ZI'})]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"\"\"What are the pros and cons of the best pizza restaurant in the city?\"\"\"\n",
        "reviews_retriever.invoke(question)\n",
        "\n",
        "# {\"context\": reviews_retriever, \"question\": RunnablePassthrough()}\n",
        "\n",
        "# review_prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1VUet58nE55"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"What are the pros and cons of the best pizza restaurant in the city?\"\"\"\n",
        "review_chain.invoke(question)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
