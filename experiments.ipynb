{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from os import getenv\n",
    "import dotenv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "# Faiss\n",
    "FAISS_REVIEWS_PATH_EUCLIDEAN = \"faiss_index_euclidean\"\n",
    "FAISS_REVIEWS_PATH_COSINE = \"faiss_index_cosine\"\n",
    "FAISS_INDEX_NAME = \"index\"\n",
    "FAISS_DISTANCE_STRATEGY_EUCLIDEAN ='EUCLIDEAN_DISTANCE'\n",
    "FAISS_DISTANCE_STRATEGY_COSINE = \"COSINE_DISTANCE\"\n",
    "LLM_MODEL_NAME = \"gemini-1.5-flash\" #\"gemini-pro\"\n",
    "EMBEDDING_MODEL_NAME = \"models/text-embedding-004\"\n",
    "EMBEDDINGS_CACHE_STORE=\"./cache/\"\n",
    "\n",
    "GOOGLE_API_KEY = getenv('GOOGLE_API_KEY')\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "store = LocalFileStore(EMBEDDINGS_CACHE_STORE)\n",
    "embedding_model = CacheBackedEmbeddings.from_bytes_store(embedding_model, store)\n",
    "\n",
    "\n",
    "vector_db = FAISS.load_local(folder_path=FAISS_REVIEWS_PATH_COSINE,\n",
    "                             embeddings=embedding_model,\n",
    "                             index_name=FAISS_INDEX_NAME,\n",
    "                             allow_dangerous_deserialization=True)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=LLM_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_str = \"\"\"\n",
    "Your job is to use Google Map restaurants and bars reviews to help people find best places to go for a meal or a drink.\n",
    "Use the following information and reviews to answer the questions. if the question is not about restaurants,\n",
    "then kindly tell the user that you can only provide assistance and answer questions related to restaurants. if the user doesn't mention the city name,\n",
    "always assume the user is asking about Padova.\n",
    "If the context provided to you does not contain the answer of the question, tell the user that there is no answer in the reviews.\n",
    "Answer context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"], template=review_template_str\n",
    "    )\n",
    ")\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(input_variables=[\"question\"], template=\"{question}\")\n",
    ")\n",
    "messages = [system_prompt, human_prompt]\n",
    "\n",
    "review_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], messages=messages\n",
    ")\n",
    "\n",
    "reviews_retriever = vector_db.as_retriever(search_kwargs={'k': 20,})\n",
    "\n",
    "review_chain = (\n",
    "    {\"context\": reviews_retriever, \"question\": RunnablePassthrough()}\n",
    "    | review_prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions():\n",
    "    with open(\"questions.txt\", mode=\"r\") as f:\n",
    "        questions = []\n",
    "        for line in f:\n",
    "            questions.append(line.split(\"\\n\")[0])\n",
    "    return questions\n",
    "\n",
    "questions = get_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Question-Answer.txt\", mode=\"w\") as f:\n",
    "    for i, question in enumerate(questions):\n",
    "        f.write(str(i) + \": \" + question + \"\\n\" + review_chain.invoke(question) + \"\\n\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_questions = [\"Give me information of some good restaurants in Via Roma, Padova.\",\n",
    "                   \"What restaurants are in Piazza Camillo Benso Conte di Cavour?\"\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Question-Answer-cosine.txt\", mode=\"r+\") as f:\n",
    "  # Write separator lines\n",
    "  f.seek(0, 2)\n",
    "  f.write(\"********************\\n********************\\n\")\n",
    "  for i, question in enumerate(extra_questions):\n",
    "    # Move the pointer to the end of the file\n",
    "    f.seek(0, 2)  \n",
    "    f.write(str(i) + \": \" + question + \"\\n\" + review_chain.invoke(question) + \"\\n\")\n",
    "    time.sleep(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
